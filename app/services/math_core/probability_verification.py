"""
ê°(â˜µ): í™•ë¥ ë¡  ê²€ì¦ ë° ì‹œê°í™” ëª¨ë“ˆ
"""

import numpy as np
import matplotlib.pyplot as plt
import scipy.stats
from math import sqrt
from ..utils.config import MATH_CONSTANTS, PLOT_CONFIG
from ..visualization.base64_encoder import save_plot_to_base64
from ...services.utils.config import configure_matplotlib

configure_matplotlib()

class ProbabilityVerification:
    """í™•ë¥ ë¡  ê²€ì¦ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.results = {}
        self.plots = {}
    
    def verify_probability_with_visualization(self):
        """ê°(â˜µ): í™•ë¥  ê²€ì¦ ë° ì‹œê°í™”"""
        print("\\n" + "=" * 50)
        print("ğŸ² ê°(â˜µ): í™•ë¥  ê²€ì¦ ë° ì‹œê°í™”")
        print("=" * 50)
        
        # 1. ì¤‘ì‹¬ê·¹í•œì •ë¦¬
        sample_sizes = [1, 5, 30, 100]
        n_samples = 1000
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        axes = axes.flatten()
        
        for i, sample_size in enumerate(sample_sizes):
            # í‘œë³¸í‰ê· ë“¤ ê³„ì‚°
            sample_means = []
            for _ in range(n_samples):
                sample = np.random.uniform(0, 1, sample_size)
                sample_means.append(np.mean(sample))
            
            # íˆìŠ¤í† ê·¸ë¨
            axes[i].hist(sample_means, bins=50, density=True, alpha=0.7, color='skyblue')
            
            # ì´ë¡ ì  ì •ê·œë¶„í¬ ì˜¤ë²„ë ˆì´
            mu = 0.5  # ê· ë“±ë¶„í¬ì˜ í‰ê· 
            sigma = 1/sqrt(12*sample_size)  # í‘œë³¸í‰ê· ì˜ í‘œì¤€í¸ì°¨
            x = np.linspace(min(sample_means), max(sample_means), 100)
            y = scipy.stats.norm.pdf(x, mu, sigma)
            axes[i].plot(x, y, 'r-', linewidth=2, label=f'Theoretical N({mu}, {sigma:.3f}Â²)')
            
            axes[i].set_title(f'Sample Size: {sample_size}')
            axes[i].set_xlabel('Sample Mean')
            axes[i].set_ylabel('Density')
            axes[i].legend()
            axes[i].grid(True, alpha=0.3)
        
        plt.suptitle('Central Limit Theorem: Distribution of Sample Means by Sample Size', fontsize=14)
        plt.tight_layout()
        plot1_base64 = save_plot_to_base64(fig)
        
        # 2. ë² ì´ì¦ˆ ì •ë¦¬
        prior = 0.01  # ì§ˆë³‘ ìœ ë³‘ë¥  1%
        sensitivity = 0.99  # ë¯¼ê°ë„ 99%
        specificity = 0.95  # íŠ¹ì´ë„ 95%
        
        # P(ì–‘ì„±|ì§ˆë³‘ìˆìŒ) Ã— P(ì§ˆë³‘ìˆìŒ) + P(ì–‘ì„±|ì§ˆë³‘ì—†ìŒ) Ã— P(ì§ˆë³‘ì—†ìŒ)
        prob_positive = sensitivity * prior + (1 - specificity) * (1 - prior)
        
        # P(ì§ˆë³‘ìˆìŒ|ì–‘ì„±) = P(ì–‘ì„±|ì§ˆë³‘ìˆìŒ) Ã— P(ì§ˆë³‘ìˆìŒ) / P(ì–‘ì„±)
        posterior = (sensitivity * prior) / prob_positive
        
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # ë² ì´ì¦ˆ ì •ë¦¬ ì‹œê°í™”
        categories = ['Prior Probability\\n(Prior)', 'Likelihood Ratio\\n(Likelihood)', 'Posterior Probability\\n(Posterior)']
        values = [prior, sensitivity/specificity, posterior]
        
        bars = ax1.bar(categories, values, color=['blue', 'green', 'red'], alpha=0.7)
        ax1.set_ylabel('Probability')
        ax1.set_title('Bayes\' Theorem: Medical Diagnosis Example')
        ax1.grid(True, alpha=0.3)
        
        # ê°’ í‘œì‹œ
        for bar, value in zip(bars, values):
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                    f'{value:.3f}', ha='center', va='bottom')
        
        # í™•ë¥  ë¶„í¬ ë¹„êµ
        x = np.linspace(0, 0.1, 1000)
        prior_dist = np.full_like(x, prior)
        posterior_dist = np.full_like(x, posterior)
        
        ax2.axvline(x=prior, color='blue', linestyle='--', linewidth=2, label=f'Prior Probability = {prior:.3f}')
        ax2.axvline(x=posterior, color='red', linestyle='-', linewidth=2, label=f'Posterior Probability = {posterior:.3f}')
        ax2.set_xlabel('Probability')
        ax2.set_ylabel('Density')
        ax2.set_title('Probability Change After Test')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        ax2.set_xlim(0, 0.5)
        
        plt.tight_layout()
        plot2_base64 = save_plot_to_base64(fig)
        
        print(f"\\nğŸ“Š í™•ë¥  ê²€ì¦ ê²°ê³¼:")
        print(f"ë² ì´ì¦ˆ ì •ë¦¬ - ì‚¬ì „í™•ë¥ : {prior:.3f}")
        print(f"ë² ì´ì¦ˆ ì •ë¦¬ - ì‚¬í›„í™•ë¥ : {posterior:.3f}")
        print(f"ë¯¼ê°ë„: {sensitivity:.3f}, íŠ¹ì´ë„: {specificity:.3f}")
        
        # ê²°ê³¼ ì €ì¥
        self.results['probability'] = {
            'prior': prior,
            'posterior': posterior,
            'sensitivity': sensitivity,
            'specificity': specificity,
            'likelihood_ratio': sensitivity / (1 - specificity)
        }
        
        self.plots['probability'] = {
            'central_limit_theorem': plot1_base64,
            'bayes_theorem': plot2_base64
        }
        
        return self.results['probability'], self.plots['probability']
