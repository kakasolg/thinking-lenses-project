"""
ê±´(â˜°): ì›ì£¼ìœ¨ Ï€ ê²€ì¦ ë° ì‹œê°í™” ëª¨ë“ˆ
"""

import numpy as np
import matplotlib.pyplot as plt
from math import pi, atan
from ..utils.config import MATH_CONSTANTS, PLOT_CONFIG
from ..visualization.base64_encoder import save_plot_to_base64

class PiVerification:
    """ì›ì£¼ìœ¨ Ï€ ê²€ì¦ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.results = {}
        self.plots = {}
    
    def verify_pi_with_visualization(self, precision=1000):
        """ê±´(â˜°): ì›ì£¼ìœ¨ Ï€ ê²€ì¦ ë° ì‹œê°í™”"""
        print("=" * 50)
        print("ğŸ”µ ê±´(â˜°): ì›ì£¼ìœ¨ Ï€ ê²€ì¦ ë° ì‹œê°í™”")
        print("=" * 50)
        
        # 1. ëª¬í…Œì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜
        n_points = 50000
        x = np.random.uniform(-1, 1, n_points)
        y = np.random.uniform(-1, 1, n_points)
        distances = np.sqrt(x**2 + y**2)
        inside_circle = distances <= 1
        pi_estimate = 4 * np.sum(inside_circle) / n_points
        
        # ì‹œê°í™” 1: ëª¬í…Œì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # ì ë“¤ ì‹œê°í™” (ìƒ˜í”Œë§Œ)
        sample_size = 2000
        sample_idx = np.random.choice(n_points, sample_size, replace=False)
        colors = ['red' if inside_circle[i] else 'blue' for i in sample_idx]
        ax1.scatter(x[sample_idx], y[sample_idx], c=colors, alpha=0.6, s=1)
        
        # ë‹¨ìœ„ì› ê·¸ë¦¬ê¸°
        theta = np.linspace(0, 2*pi, 100)
        ax1.plot(np.cos(theta), np.sin(theta), 'black', linewidth=2)
        ax1.set_xlim(-1.1, 1.1)
        ax1.set_ylim(-1.1, 1.1)
        ax1.set_aspect('equal')
        ax1.set_title(f'Monte Carlo Simulation\nÏ€ ~ {pi_estimate:.6f}', fontsize=12)
        ax1.grid(True, alpha=0.3)
        
        # ìˆ˜ë ´ì„± ì‹œê°í™”
        sample_sizes = np.arange(1000, n_points, 1000)
        pi_estimates = []
        for size in sample_sizes:
            pi_est = 4 * np.sum(inside_circle[:size]) / size
            pi_estimates.append(pi_est)
        
        ax2.plot(sample_sizes, pi_estimates, 'b-', alpha=0.7, label='Monte Carlo Estimate')
        ax2.axhline(y=pi, color='red', linestyle='--', label=f'Actual Ï€ = {pi:.6f}')
        ax2.set_xlabel('Sample Size')
        ax2.set_ylabel('Ï€ Estimate')
        ax2.set_title('Convergence of Ï€ Estimate')
        ax2.grid(True, alpha=0.3)
        ax2.legend()
        
        plt.tight_layout()
        plot1_base64 = save_plot_to_base64(fig)
        
        # 2. ë‹¤ì–‘í•œ Ï€ ê³„ì‚° ë°©ë²•ë“¤ ë¹„êµ
        methods = {
            'NumPy': np.pi,
            'Leibniz Series': self._calculate_pi_leibniz(10000),
            'Machin-like Formula': self._calculate_pi_machin(100),
            'Monte Carlo': pi_estimate,
            'Wallis Product': self._calculate_pi_wallis(10000)
        }
        
        print("\\nğŸ”¢ ë‹¤ì–‘í•œ Ï€ ê³„ì‚° ë°©ë²• ë¹„êµ:")
        for method, value in methods.items():
            error = abs(value - pi)
            print(f"{method:12s}: {value:.6f} (ì˜¤ì°¨: {error:.6f})")
        
        # ì‹œê°í™” 2: ë°©ë²•ë³„ ë¹„êµ
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        method_names = list(methods.keys())
        values = list(methods.values())
        errors = [abs(v - pi) for v in values]
        
        # ë§‰ëŒ€ ê·¸ë˜í”„
        bars = ax1.bar(method_names, values, alpha=0.7, color=['blue', 'green', 'orange', 'red', 'purple'])
        ax1.axhline(y=pi, color='black', linestyle='--', label=f'Actual Ï€ = {pi:.6f}')
        ax1.set_ylabel('Ï€ Value')
        ax1.set_title('Results by Ï€ Calculation Method')
        ax1.tick_params(axis='x', rotation=45)
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # ì˜¤ì°¨ ê·¸ë˜í”„
        ax2.bar(method_names, errors, alpha=0.7, color=['blue', 'green', 'orange', 'red', 'purple'])
        ax2.set_ylabel('Absolute Error')
        ax2.set_title('Error by Ï€ Calculation Method')
        ax2.tick_params(axis='x', rotation=45)
        ax2.set_yscale('log')
        ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plot2_base64 = save_plot_to_base64(fig)
        
        # ê²°ê³¼ ì €ì¥
        self.results['pi'] = {
            'monte_carlo': pi_estimate,
            'leibniz': methods['Leibniz Series'],
            'machin': methods['Machin-like Formula'],
            'wallis': methods['Wallis Product'],
            'numpy': np.pi,
            'actual': pi
        }
        
        self.plots['pi'] = {
            'monte_carlo_simulation': plot1_base64,
            'methods_comparison': plot2_base64
        }
        
        return self.results['pi'], self.plots['pi']
    
    def _calculate_pi_machin(self, n_terms):
        """ë§ˆì¹œ ê³µì‹ìœ¼ë¡œ Ï€ ê³„ì‚°"""
        def arctan_series(x, n_terms):
            result = 0
            for n in range(n_terms):
                term = (-1)**n * (x**(2*n+1)) / (2*n+1)
                result += term
            return result
        
        pi_estimate = 4 * (4 * arctan_series(1/5, n_terms) - arctan_series(1/239, n_terms))
        return pi_estimate
    
    def _calculate_pi_leibniz(self, n_terms):
        """ë¼ì´í”„ë‹ˆì¸  ê¸‰ìˆ˜ë¡œ Ï€ ê³„ì‚°"""
        pi_estimate = 0
        for i in range(n_terms):
            pi_estimate += (-1)**i / (2*i + 1)
        return 4 * pi_estimate
    
    def _calculate_pi_wallis(self, n_terms):
        """ì›”ë¦¬ìŠ¤ ê³±ìœ¼ë¡œ Ï€ ê³„ì‚°"""
        product = 1
        for i in range(1, n_terms + 1):
            product *= (4 * i**2) / (4 * i**2 - 1)
        return 2 * product
